{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import helperfunctions\n",
    "from ML_functions import fun_load_data, fun_preprocessing, fun_fit_tuning\n",
    "from ML_functions import fun_convert_time\n",
    "from ML_functions import fun_scaled_neg_MAPE, fun_scaled_neg_RMSE, fun_predict_with_scaling, fun_tuning_results, fun_scores\n",
    "\n",
    "# Assign string 'TSP' or 'CVRP' to the following variable to define the optimization problem\n",
    "optimization_problem = 'TSP'\n",
    "train_size = 0.7\n",
    "\n",
    "# Load data\n",
    "data = fun_load_data(optimization_problem)\n",
    "X, y, train_data = fun_preprocessing(data)\n",
    "\n",
    "# Create a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scaling the train and test scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function make predictions with a model, scale the predictions and compute the MAPE and RMSE for the train or test set\n",
    "def fun_predict_with_scaling(model, X_train, y_train, X_predict, y_true, apply_scaling):\n",
    "    \n",
    "    # Fit model on train data and get predictions for X_predict (X_predict usually is X_test, but the prediction for X_train is also possible to get the train score)\n",
    "    try: # If the model is already fitted (e.g. a grid search model after the tuning), you can directly make the predictions\n",
    "        y_pred = model.predict(X_predict)\n",
    "        fit_time = None\n",
    "    except:\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_predict)\n",
    "        fit_time = fun_convert_time(start=start, end=time.time())\n",
    "    \n",
    "    # Improve predictions: Sum of predicted Shapley values must be equal to the total costs for all instances\n",
    "    if (apply_scaling == True):\n",
    "        \n",
    "        # Connect the X_predict Data Frame with the true y labels of y_true; then assighn the predictions as a columns to the Data Frame\n",
    "        Xy_train = pd.merge(left=X_predict, right=y_true, left_index=True, right_index=True)\n",
    "        Xy_train_pred = Xy_train.assign(Predictions=pd.Series(data=y_pred, index=X_predict.index))\n",
    "        \n",
    "        # Compute the sum of predicted Shapley values and the sum of true Shapley values (the sum of the predicted Shapley values should be equal to the total costs/sum of all Shapley values of an instance)\n",
    "        Xy_train_pred['Sum of Predictions'] = Xy_train_pred.groupby('Instance ID')['Predictions'].transform('sum')\n",
    "        Xy_train_pred['Sum of Costs (Shapley values)'] = Xy_train_pred.groupby('Instance ID')['Shapley Value'].transform('sum')\n",
    "        \n",
    "        # Compute new predictions in column 'Improved Predictions' and get all predictions as a pd.Series; optionally view the Data Frame Xy_train_pred\n",
    "        Xy_train_pred['Improved Predictions'] = Xy_train_pred['Predictions'] * (Xy_train_pred['Sum of Costs (Shapley values)'] / Xy_train_pred['Sum of Predictions'])\n",
    "        y_pred = Xy_train_pred['Improved Predictions']\n",
    "        #display(Xy_train_pred[['Instance ID', 'Number Customers', 'Total Costs', 'Sum of Costs (Shapley values)', 'Predictions', 'Sum of Predictions', 'Improved Predictions', 'Shapley Value']].sort_index().head(12))\n",
    "    \n",
    "    # If the scaling is not applied, just add the correct indices to the predictions for the categorical scores later on\n",
    "    else: y_pred = pd.Series(data=y_pred, index=X_predict.index)\n",
    "\n",
    "    # Compute errors\n",
    "    MAPE_score = np.round(mean_absolute_percentage_error(y_true=y_true, y_pred=y_pred), 6) * 100\n",
    "    RMSE_score = np.round(mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False), 4)\n",
    "\n",
    "    return MAPE_score, RMSE_score, y_pred, fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute train and test scores\n",
    "def fun_scores(model, X_train, y_train, X_test=None, y_test=None, apply_scaling=True, compute_test_scores=False):\n",
    "\n",
    "    # Get CV train scores of a grid search model\n",
    "    if (hasattr(model, 'best_score_')):\n",
    "        MAPE_train = - np.round(model.best_score_, 6) * 100\n",
    "        RMSE_train, cv_computation_time = None, None\n",
    "        print('CV MAPE (scaled) train data:  {} %'.format(MAPE_train)) \n",
    "        \n",
    "        # Show best parameter combination\n",
    "        print('\\nBest model / parameter combination:')\n",
    "        if (len(model.get_params()) <= 10): display(model.best_estimator_)\n",
    "        else: display(model.best_params_)\n",
    "\n",
    "    # Compute CV train scores if model is a usual estimator and measure CV computation time\n",
    "    else:\n",
    "        # Get MAPE and RMSE scores from the model's scaled predictions and unscaled predictions\n",
    "        start = time.time()\n",
    "        cv_scores = cross_validate(estimator=model, X=X_train, y=y_train, cv=3, n_jobs=-1,\n",
    "                                   scoring={'scaled_mape': fun_scaled_neg_MAPE,\n",
    "                                            'scaled_rmse': fun_scaled_neg_RMSE,\n",
    "                                            'original_neg_mape': 'neg_mean_absolute_percentage_error',\n",
    "                                            'original_neg_rmse': 'neg_root_mean_squared_error'})\n",
    "        cv_computation_time = fun_convert_time(start=start, end=time.time())\n",
    "\n",
    "        # Print train scores for either the scaled predictions or the unscaled predictions\n",
    "        if (apply_scaling == True):\n",
    "            MAPE_train = - np.round(cv_scores['test_scaled_mape'].mean(), 6) * 100\n",
    "            RMSE_train = - np.round(cv_scores['test_scaled_rmse'].mean(), 4)\n",
    "        else:\n",
    "            MAPE_train = - np.round(cv_scores['test_original_neg_mape'].mean(), 6) * 100\n",
    "            RMSE_train = - np.round(cv_scores['test_original_neg_rmse'].mean(), 4)\n",
    "        print('CV MAPE ({}) train data:  {} %'.format('scaled' if apply_scaling else 'original', MAPE_train))\n",
    "        print('CV RMSE ({}) train data: {}'.format('scaled' if apply_scaling else 'original', RMSE_train))        \n",
    "        print('CV computation time:', cv_computation_time)\n",
    "    \n",
    "    # Compute test scores if compute_test_scores == True\n",
    "    if (compute_test_scores == True):\n",
    "        if (X_test is None) or (y_test is None): raise ValueError(\"You need to define X_test and y_test to compute the test scores.\")\n",
    "        # Get MAPE and RMSE scores from the model's scaled predictions and update scores\n",
    "        MAPE_test, RMSE_test, y_pred, fit_time = fun_predict_with_scaling(model, X_train, y_train, X_test, y_test, apply_scaling)\n",
    "        MAPE = {'Train data': MAPE_train, 'Test data': MAPE_test}\n",
    "        RMSE = {'Train data': RMSE_train, 'Test data': RMSE_test}\n",
    "\n",
    "        # Compute error measures for each instance size group individually\n",
    "        # Group X by instance size and apply for each group the error measure fct. Use indices of each group to select the regarding true y values and the improved predictions\n",
    "        entities = 'Customers' if ('Number Customers' in X_train.columns) else 'Items' # Feature name in TSP and CVRP: 'Number Customers', Bin_Packing: 'Number Items'\n",
    "        MAPE_cat = X_test.groupby(by='Number ' + entities).apply(lambda group: mean_absolute_percentage_error(y_true=y_test.loc[group.index], y_pred=y_pred.loc[group.index]))\n",
    "        RMSE_cat = X_test.groupby(by='Number ' + entities).apply(lambda group: mean_squared_error(y_true=y_test.loc[group.index], y_pred=y_pred.loc[group.index], squared=False))\n",
    "\n",
    "        # Round results and merge them into a data frame\n",
    "        MAPE_cat = np.round(MAPE_cat, 6) * 100\n",
    "        RMSE_cat = np.round(RMSE_cat, 4)\n",
    "        df = pd.DataFrame(data=[MAPE_cat, RMSE_cat], index=['MAPE', 'RMSE'])\n",
    "        df['Mean'] = [MAPE_test, RMSE_test]\n",
    "\n",
    "        # Print results and show data frame of instance size groups\n",
    "        print('\\nMAPE ({}) test data:  {} %'.format('scaled' if apply_scaling else 'original', MAPE_test))\n",
    "        print('RMSE ({}) test data: {}'.format('scaled' if apply_scaling else 'original', RMSE_test))\n",
    "        if (fit_time is not None): print('Model fit time:', fit_time)\n",
    "        print('\\nMAPE and RMSE on test data per instance size:'), display(df)\n",
    "\n",
    "        return {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': cv_computation_time, 'Fit model time': fit_time, 'Scores per instance size': df}\n",
    "\n",
    "    else: return {'MAPE': MAPE_train, 'RMSE': RMSE_train, 'CV computation time': cv_computation_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data:  23.7618 %\n",
      "CV RMSE (scaled) train data: 7.6303\n",
      "CV computation time: 3s\n",
      "\n",
      "MAPE (scaled) test data:  19.1927 %\n",
      "RMSE (scaled) test data: 3.8665\n",
      "Model fit time: 0s\n",
      "\n",
      "MAPE and RMSE on test data per instance size:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number Customers</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>14.3279</td>\n",
       "      <td>13.5322</td>\n",
       "      <td>13.4337</td>\n",
       "      <td>13.4527</td>\n",
       "      <td>15.2197</td>\n",
       "      <td>14.1552</td>\n",
       "      <td>17.9915</td>\n",
       "      <td>22.0098</td>\n",
       "      <td>36.5798</td>\n",
       "      <td>19.1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.7701</td>\n",
       "      <td>3.9908</td>\n",
       "      <td>3.6785</td>\n",
       "      <td>3.0414</td>\n",
       "      <td>3.0327</td>\n",
       "      <td>2.9727</td>\n",
       "      <td>3.2028</td>\n",
       "      <td>4.0646</td>\n",
       "      <td>5.2378</td>\n",
       "      <td>3.8665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number Customers        6        7        8        9       10       11  \\\n",
       "MAPE              14.3279  13.5322  13.4337  13.4527  15.2197  14.1552   \n",
       "RMSE               4.7701   3.9908   3.6785   3.0414   3.0327   2.9727   \n",
       "\n",
       "Number Customers       12       13       14     Mean  \n",
       "MAPE              17.9915  22.0098  36.5798  19.1927  \n",
       "RMSE               3.2028   4.0646   5.2378   3.8665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from ML_functions import fun_tuning_results, fun_predict_with_scaling, fun_scores\n",
    "\n",
    "# Create model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "model_results_dict = fun_scores(model=lr, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, compute_test_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scaling the cross-validation scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the scaled MAPE in a CV process\n",
    "# (Scale the predictions, such that the sum of all predicitons per instance is equal to the sum of the Shapley values of that instance)\n",
    "def fun_scaled_neg_MAPE(estimator, X, y_true):\n",
    "    # Make predictions\n",
    "    y_pred = estimator.predict(X)\n",
    "    \n",
    "    # Connect the X_predict Data Frame with the true y labels of y_true; then assighn the predictions as a columns to the Data Frame\n",
    "    Xy_train = pd.merge(left=X, right=y_true, left_index=True, right_index=True)\n",
    "    Xy_train_pred = Xy_train.assign(Predictions=pd.Series(data=y_pred, index=X.index))\n",
    "    \n",
    "    # Compute the sum of predicted Shapley values and the sum of true Shapley values (the sum of the predicted Shapley values should be equal to the total costs/sum of all Shapley values of an instance)\n",
    "    Xy_train_pred['Sum of Predictions'] = Xy_train_pred.groupby('Instance ID')['Predictions'].transform('sum')\n",
    "    Xy_train_pred['Sum of Costs (Shapley values)'] = Xy_train_pred.groupby('Instance ID')['Shapley Value'].transform('sum')\n",
    "    \n",
    "    # Compute new predictions\n",
    "    y_pred = Xy_train_pred['Predictions'] * (Xy_train_pred['Sum of Costs (Shapley values)'] / Xy_train_pred['Sum of Predictions'])\n",
    "\n",
    "    return - np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "# Function to compute the scaled RMSE  in a CV process\n",
    "def fun_scaled_neg_RMSE(estimator, X, y_true):\n",
    "    # Make predictions\n",
    "    y_pred = estimator.predict(X)\n",
    "    \n",
    "    # Connect the X_predict Data Frame with the true y labels of y_true; then assighn the predictions as a columns to the Data Frame\n",
    "    Xy_train = pd.merge(left=X, right=y_true, left_index=True, right_index=True)\n",
    "    Xy_train_pred = Xy_train.assign(Predictions=pd.Series(data=y_pred, index=X.index))\n",
    "    \n",
    "    # Compute the sum of predicted Shapley values and the sum of true Shapley values (the sum of the predicted Shapley values should be equal to the total costs/sum of all Shapley values of an instance)\n",
    "    Xy_train_pred['Sum of Predictions'] = Xy_train_pred.groupby('Instance ID')['Predictions'].transform('sum')\n",
    "    Xy_train_pred['Sum of Costs (Shapley values)'] = Xy_train_pred.groupby('Instance ID')['Shapley Value'].transform('sum')\n",
    "    \n",
    "    # Compute new predictions\n",
    "    y_pred = Xy_train_pred['Predictions'] * (Xy_train_pred['Sum of Costs (Shapley values)'] / Xy_train_pred['Sum of Predictions'])\n",
    "\n",
    "    return - np.sqrt(np.mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Scaling during Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data:  13.9566 %\n",
      "CV RMSE (scaled) train data:  2.963\n",
      "\n",
      "CV MAPE (original) train data:  16.150100000000002 %\n",
      "CV RMSE (original) train data:  3.2191\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(estimator=lr, X=X_train, y=y_train, cv=3,\n",
    "                           scoring={'scaled_neg_mape': fun_scaled_neg_MAPE,\n",
    "                                    'scaled_neg_rmse': fun_scaled_neg_RMSE,\n",
    "                                    'original_neg_mape': 'neg_mean_absolute_percentage_error',\n",
    "                                    'original_neg_rmse': 'neg_root_mean_squared_error'}, \n",
    "                           n_jobs=1, verbose=False)\n",
    "\n",
    "MAPE1 = - np.round(cv_scores['test_scaled_neg_mape'].mean(), 6) * 100\n",
    "RMSE1 = - np.round(cv_scores['test_scaled_neg_rmse'].mean(), 4)\n",
    "MAPE2 = - np.round(cv_scores['test_original_neg_mape'].mean(), 6) * 100\n",
    "RMSE2 = - np.round(cv_scores['test_original_neg_rmse'].mean(), 4)\n",
    "\n",
    "# Print train scores\n",
    "print('CV MAPE (scaled) train data:  {} %'.format(MAPE1))\n",
    "print('CV RMSE (scaled) train data: ', RMSE1)\n",
    "print('\\nCV MAPE (original) train data:  {} %'.format(MAPE2))\n",
    "print('CV RMSE (original) train data: ', RMSE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Scaling during Hyperparametertunging with Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Tuning fit time: 3m, 41s\n",
      "CV MAPE (scaled) train data:  20.0617 %\n",
      "\n",
      "Best model / parameter combination:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 10, 'scaler': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAPE (scaled) test data:  20.2527 %\n",
      "RMSE (scaled) test data: 3.8038\n",
      "\n",
      "MAPE and RMSE on test data per instance size:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number Customers</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>18.1360</td>\n",
       "      <td>19.8731</td>\n",
       "      <td>20.5779</td>\n",
       "      <td>19.2701</td>\n",
       "      <td>21.5637</td>\n",
       "      <td>23.9496</td>\n",
       "      <td>18.9224</td>\n",
       "      <td>18.4711</td>\n",
       "      <td>20.7266</td>\n",
       "      <td>20.2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>5.4058</td>\n",
       "      <td>4.6265</td>\n",
       "      <td>4.2630</td>\n",
       "      <td>3.9368</td>\n",
       "      <td>3.9171</td>\n",
       "      <td>3.5010</td>\n",
       "      <td>3.3223</td>\n",
       "      <td>3.1965</td>\n",
       "      <td>3.1770</td>\n",
       "      <td>3.8038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number Customers        6        7        8        9       10       11  \\\n",
       "MAPE              18.1360  19.8731  20.5779  19.2701  21.5637  23.9496   \n",
       "RMSE               5.4058   4.6265   4.2630   3.9368   3.9171   3.5010   \n",
       "\n",
       "Number Customers       12       13       14     Mean  \n",
       "MAPE              18.9224  18.4711  20.7266  20.2527  \n",
       "RMSE               3.3223   3.1965   3.1770   3.8038  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores of different parameter combinations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>converted_mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.200617</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.200644</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.200801</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.201046</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.201471</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.202578</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.205280</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.211307</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.211429</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.211632</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.212286</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.213332</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.214244</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.217131</td>\n",
       "      <td>0s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param_scaler param_knn__n_neighbors  mean_test_score  \\\n",
       "0   StandardScaler()                     10        -0.200617   \n",
       "1   StandardScaler()                      9        -0.200644   \n",
       "2   StandardScaler()                      8        -0.200801   \n",
       "3   StandardScaler()                     11        -0.201046   \n",
       "4   StandardScaler()                      7        -0.201471   \n",
       "5   StandardScaler()                      6        -0.202578   \n",
       "6   StandardScaler()                      5        -0.205280   \n",
       "7     MinMaxScaler()                     10        -0.211307   \n",
       "8     MinMaxScaler()                     11        -0.211429   \n",
       "9     MinMaxScaler()                      9        -0.211632   \n",
       "10    MinMaxScaler()                      8        -0.212286   \n",
       "11    MinMaxScaler()                      7        -0.213332   \n",
       "12    MinMaxScaler()                      6        -0.214244   \n",
       "13    MinMaxScaler()                      5        -0.217131   \n",
       "\n",
       "   converted_mean_fit_time  \n",
       "0                       0s  \n",
       "1                       0s  \n",
       "2                       0s  \n",
       "3                       0s  \n",
       "4                       0s  \n",
       "5                       0s  \n",
       "6                       0s  \n",
       "7                       0s  \n",
       "8                       0s  \n",
       "9                       0s  \n",
       "10                      0s  \n",
       "11                      0s  \n",
       "12                      0s  \n",
       "13                      0s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid search cross validation with data scaling\n",
    "pipe = Pipeline(steps=[('scaler', None), \n",
    "                       ('knn', KNeighborsRegressor())])\n",
    "\n",
    "param_grid = {'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "              'knn__n_neighbors': list(np.arange(start=7, stop=12))}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3,\n",
    "                           scoring=fun_scaled_neg_MAPE, verbose=True, n_jobs=-1)\n",
    "fit_time = fun_fit_tuning(search_method=grid_search, X_train=X_train, y_train=y_train, file_name=optimization_problem + '_KNN')\n",
    "\n",
    "# View results of grid search cross validation\n",
    "model_results_dict = fun_scores(model=grid_search, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, compute_test_scores=True)\n",
    "\n",
    "# View grid search CV scores of all parameter combinations\n",
    "results_df = fun_tuning_results(search_method=grid_search, search_space=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 10, 'scaler': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data:  20.0617 %\n",
      "CV RMSE (scaled) train data: 3.9645\n",
      "CV computation time: 1m, 12s\n",
      "\n",
      "MAPE (scaled) test data:  20.2527 %\n",
      "RMSE (scaled) test data: 3.8038\n",
      "Model fit time: 1m, 5s\n",
      "\n",
      "MAPE and RMSE on test data per instance size:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Number Customers</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>18.1360</td>\n",
       "      <td>19.8731</td>\n",
       "      <td>20.5779</td>\n",
       "      <td>19.2701</td>\n",
       "      <td>21.5637</td>\n",
       "      <td>23.9496</td>\n",
       "      <td>18.9224</td>\n",
       "      <td>18.4711</td>\n",
       "      <td>20.7266</td>\n",
       "      <td>20.2527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>5.4058</td>\n",
       "      <td>4.6265</td>\n",
       "      <td>4.2630</td>\n",
       "      <td>3.9368</td>\n",
       "      <td>3.9171</td>\n",
       "      <td>3.5010</td>\n",
       "      <td>3.3223</td>\n",
       "      <td>3.1965</td>\n",
       "      <td>3.1770</td>\n",
       "      <td>3.8038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Number Customers        6        7        8        9       10       11  \\\n",
       "MAPE              18.1360  19.8731  20.5779  19.2701  21.5637  23.9496   \n",
       "RMSE               5.4058   4.6265   4.2630   3.9368   3.9171   3.5010   \n",
       "\n",
       "Number Customers       12       13       14     Mean  \n",
       "MAPE              18.9224  18.4711  20.7266  20.2527  \n",
       "RMSE               3.3223   3.1965   3.1770   3.8038  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ML_functions import fun_load_best_params\n",
    "\n",
    "# Load best parameters of the model\n",
    "best_params = fun_load_best_params(optimization_problem + '_KNN_best_params.pkl')\n",
    "\n",
    "# Create a pipline and set best_params as parameters\n",
    "pipe = Pipeline(steps=[('scaler', None), \n",
    "                       ('knn', KNeighborsRegressor())])\n",
    "pipe.set_params(**best_params)\n",
    "\n",
    "# Estimate model performance with cross-validation on the train set and get scores on test set (scoring: MAPE and RMSE)\n",
    "model_results_dict = fun_scores(model=pipe, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, compute_test_scores=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
