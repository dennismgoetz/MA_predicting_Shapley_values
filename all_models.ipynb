{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# import helperfunctions\n",
    "from helperfunctions import fun_load_file, fun_preprocessing, fun_split_X_y\n",
    "from helperfunctions import fun_convert_time\n",
    "from helperfunctions import fun_train_score\n",
    "\n",
    "# start time count and load data\n",
    "start_script = time.time()\n",
    "data = fun_load_file(path='01_data\\\\01_TSP', name='combined_train_instances_dennis.xlsx')\n",
    "train_data = fun_preprocessing(data)\n",
    "X, y = fun_split_X_y(train_data)\n",
    "\n",
    "# create a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# create a smaller train set for svm\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X, y, test_size=0.6, random_state=0)\n",
    "\n",
    "# save number of features and train sizes\n",
    "n_features = X_train.shape[1]\n",
    "train_size = f'{int(np.round(100 * len(X_train)/len(X)))} %'\n",
    "train_size_small = f'{int(np.round(100 * len(X_train_small)/len(X)))} %'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  51.7483 %\n",
      "  CV RMSE train data:  12.4712\n",
      "  CV computation time: 12 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(knn, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict = {}\n",
    "results_dict['KNN'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  16.6011 %\n",
      "  CV RMSE train data:  3.293\n",
      "  CV computation time: 2 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "lr = LinearRegression()\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(lr, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Linear Regression'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rigde Regression (L2-Regularization)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  16.6023 %\n",
      "  CV RMSE train data:  3.2931\n",
      "  CV computation time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "ridge = Ridge(alpha=1) #alpha=0: linear regression without regularization\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(ridge, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Ridge Regression'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Regression (L1-Regularization)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  19.7085 %\n",
      "  CV RMSE train data:  4.1037\n",
      "  CV computation time: 3 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "lasso = Lasso(alpha=1, max_iter=10000) #higher alpha means higher regularization and lower model complexity (less overfitting)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(lasso, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Lasso Regression'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: StandardScaler()\n",
      "  CV MAPE train data:  16.8384 %\n",
      "  CV RMSE train data:  3.3782\n",
      "  CV computation time: 1 min, 58 sec\n",
      "Method: MinMaxScaler()\n",
      "  CV MAPE train data:  16.902800000000003 %\n",
      "  CV RMSE train data:  3.3847\n",
      "  CV computation time: 1 min, 10 sec\n",
      "Method: RobustScaler()\n",
      "  CV MAPE train data:  16.8364 %\n",
      "  CV RMSE train data:  3.3775\n",
      "  CV computation time: 1 min, 58 sec\n"
     ]
    }
   ],
   "source": [
    "# compare the scaling methods\n",
    "best_MAPE = 100\n",
    "for i in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "\n",
    "    # scale the train set first\n",
    "    scaler = i\n",
    "    X_train_scaled = scaler.fit_transform(X_train_small)\n",
    "\n",
    "    # create model and fit it on train set (default parameters)\n",
    "    svm = SVR(kernel='linear', C=1) #regularization parameter C controls trade-off between maximizing the margin and minimizing the classification error (how important it is to satisfy the constraint)\n",
    "\n",
    "    # estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "    print('Method:', i)\n",
    "    MAPE, RMSE, computation_time = fun_train_score(svm, X_train_scaled, y_train_small, cv=3, return_results=True)\n",
    "\n",
    "    # save best result\n",
    "    if MAPE < best_MAPE:\n",
    "        best_MAPE = MAPE\n",
    "        best_RMSE = RMSE\n",
    "        best_computation_time = computation_time\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Linear SVM'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': best_computation_time, 'Train size': train_size_small}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  10.8992 %\n",
      "  CV RMSE train data:  3.6824\n",
      "  CV computation time: 10 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "tree = DecisionTreeRegressor(max_depth=None, max_leaf_nodes=None, min_samples_leaf=1, \n",
    "                             min_impurity_decrease=0, random_state=0)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(tree, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Decision Tree'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensebmles of Decision Trees**\n",
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  6.6329 %\n",
      "  CV RMSE train data:  2.1148\n",
      "  CV computation time: 12 min, 55 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "forest = RandomForestRegressor(n_estimators=100, max_features=n_features, max_depth=None, \n",
    "                               max_leaf_nodes=None, min_samples_leaf=1, min_impurity_decrease=0,\n",
    "                               random_state=0, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(forest, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Random Forest'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Regression Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  8.5405 %\n",
      "  CV RMSE train data:  2.2269\n",
      "  CV computation time: 4 min, 0 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "gbrt = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, #lower learning rate requires more trees\n",
    "                                 max_depth=3, max_leaf_nodes=None,\n",
    "                                 random_state=0)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(gbrt, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Gradient Boosting Regression Tree'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extreme Gradient Boosting: XGBoost-Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV MAPE train data:  5.815300000000001 %\n",
      "  CV RMSE train data:  1.6959\n",
      "  CV computation time: 10 sec\n"
     ]
    }
   ],
   "source": [
    "# create model and fit it on train set (default parameters)\n",
    "xgboost = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                           n_estimators=None, \n",
    "                           learning_rate=None,\n",
    "                           max_depth=None)\n",
    "\n",
    "# estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "MAPE, RMSE, computation_time = fun_train_score(xgboost, X_train, y_train, cv=10, return_results=True)\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['XGBoost'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Support Vector Machines with Kernels - Kernel Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: StandardScaler()\n",
      "  CV MAPE train data:  10.5322 %\n",
      "  CV RMSE train data:  3.8303\n",
      "  CV computation time: 1 min, 31 sec\n",
      "Method: MinMaxScaler()\n",
      "  CV MAPE train data:  18.8202 %\n",
      "  CV RMSE train data:  3.9461\n",
      "  CV computation time: 1 min, 42 sec\n",
      "Method: RobustScaler()\n",
      "  CV MAPE train data:  9.282300000000001 %\n",
      "  CV RMSE train data:  2.8699\n",
      "  CV computation time: 1 min, 34 sec\n"
     ]
    }
   ],
   "source": [
    "# compare the scaling methods\n",
    "best_MAPE = 100\n",
    "for i in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "\n",
    "    # scale the train set first\n",
    "    scaler = i\n",
    "    X_train_scaled = scaler.fit_transform(X_train_small)\n",
    "\n",
    "    # create model and fit it on train set (default parameters)\n",
    "    svm = SVR(kernel='rbf', C=1, gamma=1/n_features)\n",
    "\n",
    "    # estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "    print('Method:', i)\n",
    "    MAPE, RMSE, computation_time = fun_train_score(svm, X_train_scaled, y_train_small, cv=3, return_results=True)\n",
    "\n",
    "    # save best result\n",
    "    if MAPE < best_MAPE:\n",
    "        best_MAPE = MAPE\n",
    "        best_RMSE = RMSE\n",
    "        best_computation_time = computation_time\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['SVM Gaussian Kernel'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': best_computation_time, 'Train size': train_size_small}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: StandardScaler()\n",
      "  CV MAPE train data:  19.8595 %\n",
      "  CV RMSE train data:  4.7058\n",
      "  CV computation time: 1 min, 7 sec\n",
      "Method: MinMaxScaler()\n",
      "  CV MAPE train data:  49.6135 %\n",
      "  CV RMSE train data:  10.6031\n",
      "  CV computation time: 58 sec\n",
      "Method: RobustScaler()\n",
      "  CV MAPE train data:  33.5229 %\n",
      "  CV RMSE train data:  7.3372\n",
      "  CV computation time: 1 min, 4 sec\n"
     ]
    }
   ],
   "source": [
    "# compare the scaling methods\n",
    "best_MAPE = 100\n",
    "for i in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "\n",
    "    # scale the train set first\n",
    "    scaler = i\n",
    "    X_train_scaled = scaler.fit_transform(X_train_small)\n",
    "\n",
    "    # create model and fit it on train set (default parameters)\n",
    "    svm = SVR(kernel='poly', C=1, gamma=1/n_features, degree=3)\n",
    "\n",
    "    # estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "    print('Method:', i)\n",
    "    MAPE, RMSE, computation_time = fun_train_score(svm, X_train_scaled, y_train_small, cv=3, return_results=True)\n",
    "\n",
    "    # save best result\n",
    "    if MAPE < best_MAPE:\n",
    "        best_MAPE = MAPE\n",
    "        best_RMSE = RMSE\n",
    "        best_computation_time = computation_time\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['SVM Polynomial Kernel'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': best_computation_time, 'Train size': train_size_small}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: StandardScaler()\n",
      "  CV MAPE train data:  3.8644 %\n",
      "  CV RMSE train data:  0.9207\n",
      "  CV computation time: 39 sec\n",
      "Method: MinMaxScaler()\n",
      "  CV MAPE train data:  4.96 %\n",
      "  CV RMSE train data:  1.1645\n",
      "  CV computation time: 10 min, 36 sec\n",
      "Method: RobustScaler()\n",
      "  CV MAPE train data:  3.8686 %\n",
      "  CV RMSE train data:  0.9121\n",
      "  CV computation time: 39 sec\n"
     ]
    }
   ],
   "source": [
    "# compare the scaling methods\n",
    "best_MAPE = 100\n",
    "for i in [StandardScaler(), MinMaxScaler(), RobustScaler()]:\n",
    "\n",
    "    # scale the train set first\n",
    "    scaler = i\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # create model and fit it on train set (default parameters)\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(100,), alpha=0.0001,\n",
    "                       activation='relu', solver='adam', max_iter=1000, random_state=0)\n",
    "\n",
    "    # estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "    print('Method:', i)\n",
    "    MAPE, RMSE, computation_time = fun_train_score(mlp, X_train_scaled, y_train, cv=3, return_results=True)\n",
    "\n",
    "    # save best result\n",
    "    if MAPE < best_MAPE:\n",
    "        best_MAPE = MAPE\n",
    "        best_RMSE = RMSE\n",
    "        best_computation_time = computation_time\n",
    "\n",
    "# save results to dictionary\n",
    "results_dict['Neural Network'] = {'MAPE': MAPE, 'RMSE': RMSE, 'CV computation time': best_computation_time, 'Train size': train_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Compare Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neural Network</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting Regression Tree</th>\n",
       "      <th>SVM Gaussian Kernel</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Ridge Regression</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Lasso Regression</th>\n",
       "      <th>SVM Polynomial Kernel</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>3.8686</td>\n",
       "      <td>5.8153</td>\n",
       "      <td>6.6329</td>\n",
       "      <td>8.5405</td>\n",
       "      <td>9.2823</td>\n",
       "      <td>10.8992</td>\n",
       "      <td>16.6011</td>\n",
       "      <td>16.6023</td>\n",
       "      <td>16.8364</td>\n",
       "      <td>19.7085</td>\n",
       "      <td>33.5229</td>\n",
       "      <td>51.7483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9121</td>\n",
       "      <td>1.6959</td>\n",
       "      <td>2.1148</td>\n",
       "      <td>2.2269</td>\n",
       "      <td>2.8699</td>\n",
       "      <td>3.6824</td>\n",
       "      <td>3.293</td>\n",
       "      <td>3.2931</td>\n",
       "      <td>3.3775</td>\n",
       "      <td>4.1037</td>\n",
       "      <td>7.3372</td>\n",
       "      <td>12.4712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV computation time</th>\n",
       "      <td>39 sec</td>\n",
       "      <td>10 sec</td>\n",
       "      <td>12 min, 55 sec</td>\n",
       "      <td>4 min, 0 sec</td>\n",
       "      <td>1 min, 34 sec</td>\n",
       "      <td>10 sec</td>\n",
       "      <td>2 sec</td>\n",
       "      <td>0 sec</td>\n",
       "      <td>1 min, 58 sec</td>\n",
       "      <td>3 sec</td>\n",
       "      <td>1 min, 7 sec</td>\n",
       "      <td>12 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train size</th>\n",
       "      <td>75 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>40 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>40 %</td>\n",
       "      <td>75 %</td>\n",
       "      <td>40 %</td>\n",
       "      <td>75 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Neural Network XGBoost   Random Forest  \\\n",
       "MAPE                        3.8686  5.8153          6.6329   \n",
       "RMSE                        0.9121  1.6959          2.1148   \n",
       "CV computation time         39 sec  10 sec  12 min, 55 sec   \n",
       "Train size                    75 %    75 %            75 %   \n",
       "\n",
       "                    Gradient Boosting Regression Tree SVM Gaussian Kernel  \\\n",
       "MAPE                                           8.5405              9.2823   \n",
       "RMSE                                           2.2269              2.8699   \n",
       "CV computation time                      4 min, 0 sec       1 min, 34 sec   \n",
       "Train size                                       75 %                40 %   \n",
       "\n",
       "                    Decision Tree Linear Regression Ridge Regression  \\\n",
       "MAPE                      10.8992           16.6011          16.6023   \n",
       "RMSE                       3.6824             3.293           3.2931   \n",
       "CV computation time        10 sec             2 sec            0 sec   \n",
       "Train size                   75 %              75 %             75 %   \n",
       "\n",
       "                        Linear SVM Lasso Regression SVM Polynomial Kernel  \\\n",
       "MAPE                       16.8364          19.7085               33.5229   \n",
       "RMSE                        3.3775           4.1037                7.3372   \n",
       "CV computation time  1 min, 58 sec            3 sec          1 min, 7 sec   \n",
       "Train size                    40 %             75 %                  40 %   \n",
       "\n",
       "                         KNN  \n",
       "MAPE                 51.7483  \n",
       "RMSE                 12.4712  \n",
       "CV computation time   12 sec  \n",
       "Train size              75 %  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total script computation time: 43 min, 19 sec\n"
     ]
    }
   ],
   "source": [
    "display(pd.DataFrame(results_dict).sort_values(by='MAPE', axis=1))\n",
    "print('Total script computation time:', fun_convert_time(start=start_script, end=time.time()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
