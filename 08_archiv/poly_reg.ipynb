{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is executed directly. :)\n",
      "Optimization problem: 'TSP'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import helperfunctions\n",
    "from ML_functions import fun_load_settings, fun_load_data, fun_preprocessing, fun_fit_tuning\n",
    "from ML_functions import fun_scaled_neg_MAPE, fun_tuning_results, fun_scores\n",
    "\n",
    "# Set the default optimization problem for the case of manual executing the script (choose either \"TSP\" or \"CVRP\")\n",
    "default_optimization_problem = \"TSP\"\n",
    "\n",
    "# Call the function to define optimization_problem based on how the notebook is executed\n",
    "# If the notebook is run by the script \"main.ipynb\", load optimization_problem from \"settings.json\". Otherwise use the default optimization problem from above\n",
    "optimization_problem = fun_load_settings(default_optimization_problem)\n",
    "\n",
    "# Load data and start the time count for the script within the function fun_load_data\n",
    "data, start_script = fun_load_data(optimization_problem)\n",
    "\n",
    "# Do the train test split during the preprocessing\n",
    "X_train, X_test, y_train, y_test, train_data = fun_preprocessing(data, train_size=0.8)\n",
    "\n",
    "# Load most important features from script \"b1_feature_selection.ipynb\" and get a list with all features\n",
    "top20_features = list(pd.read_csv(f\"02_best_features/{optimization_problem}_top20_features\"))\n",
    "all_features = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data: 6.3222000000000005 %\n",
      "CV RMSE (scaled) train data: 1.5603\n",
      "CV computation time: 31s\n"
     ]
    }
   ],
   "source": [
    "# Define the preprocessing steps for continuous features\n",
    "onehot_transformer = Pipeline(steps=[(\"binning\", KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\")),\n",
    "                                     (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "\n",
    "poly_transformer = Pipeline(steps=[(\"poly\", PolynomialFeatures(degree=3, interaction_only=False, include_bias=True))])\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[(\"onehot\", onehot_transformer, top20_features),\n",
    "                                               (\"poly\", poly_transformer, top20_features)],\n",
    "                                               remainder=\"passthrough\")\n",
    "\n",
    "# Define the model pipeline\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                       (\"lr\", LinearRegression())])\n",
    "\n",
    "# Estimate model performance with cross-validation on the train set (scoring: MAPE and RMSE)\n",
    "model_results_dict = fun_scores(model=pipe, X_train=X_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of logical CPU cores on this machine: 12 cores\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Search type': 'GridSearchCV',\n",
       " 'Parameter combinations': 12,\n",
       " 'Total tuning time': '56m, 21s',\n",
       " 'Total tuning fit time': '33m, 59s',\n",
       " 'Total tuning prediction time': '16s'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data:  4.714700000000001 %\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Best model / parameter combination:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'feature_set': 'all_features (37)',\n",
       " 'preprocessor__onehot__binning__n_bins': 10,\n",
       " 'preprocessor__poly__degree': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Cross validation scores of different parameter combinations:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_bins</th>\n",
       "      <th>degree</th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>converted_mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.047147</td>\n",
       "      <td>11m, 31s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.047497</td>\n",
       "      <td>10m, 15s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.047699</td>\n",
       "      <td>11m, 14s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.063338</td>\n",
       "      <td>12s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.063451</td>\n",
       "      <td>11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.074679</td>\n",
       "      <td>3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.074700</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>all_features (37)</td>\n",
       "      <td>-0.075966</td>\n",
       "      <td>4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.095698</td>\n",
       "      <td>2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.096062</td>\n",
       "      <td>1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>top20_features</td>\n",
       "      <td>-0.099957</td>\n",
       "      <td>1s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_bins  degree       preprocessor  mean_test_score converted_mean_fit_time\n",
       "0       10       3  all_features (37)        -0.047147                11m, 31s\n",
       "1        5       3  all_features (37)        -0.047497                10m, 15s\n",
       "2       15       3  all_features (37)        -0.047699                11m, 14s\n",
       "3       10       3     top20_features        -0.063338                     12s\n",
       "4        5       3     top20_features        -0.063451                     11s\n",
       "5       15       3     top20_features        -0.063832                     13s\n",
       "6       10       2  all_features (37)        -0.074679                      3s\n",
       "7       15       2  all_features (37)        -0.074700                      7s\n",
       "8        5       2  all_features (37)        -0.075966                      4s\n",
       "9       15       2     top20_features        -0.095698                      2s\n",
       "10      10       2     top20_features        -0.096062                      1s\n",
       "11       5       2     top20_features        -0.099957                      1s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the number of CPU cores on the machine\n",
    "print(f\"Total number of logical CPU cores on this machine: {multiprocessing.cpu_count()} cores\")\n",
    "\n",
    "# Define the preprocessing steps for continuous features\n",
    "onehot_transformer = Pipeline(steps=[(\"binning\", KBinsDiscretizer(encode=\"ordinal\", strategy=\"uniform\")),\n",
    "                                     (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor_top20 = ColumnTransformer(transformers=[(\"onehot\", onehot_transformer, top20_features), \n",
    "                                                     (\"poly\", PolynomialFeatures(interaction_only=False, include_bias=True), top20_features)], \n",
    "                                                     remainder=\"passthrough\")\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor_all = ColumnTransformer(transformers=[(\"onehot\", onehot_transformer, top20_features), \n",
    "                                                    (\"poly\", PolynomialFeatures(interaction_only=False, include_bias=True), all_features)], \n",
    "                                                    remainder=\"passthrough\")\n",
    "\n",
    "# Define the model pipeline\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", None),\n",
    "                       (\"lr\", LinearRegression())])\n",
    "\n",
    "param_grid = [{\"preprocessor\": [preprocessor_top20],\n",
    "              \"preprocessor__onehot__binning__n_bins\": [5, 10, 15], \n",
    "              \"preprocessor__poly__degree\": [2, 3]},\n",
    "              {\"preprocessor\": [preprocessor_all],\n",
    "              \"preprocessor__onehot__binning__n_bins\": [5, 10, 15], \n",
    "              \"preprocessor__poly__degree\": [2, 3]}]\n",
    "\n",
    "# Set up GridSearchCV\n",
    "cv_n_jobs = 2 # Reduce number of cores (n_jobs) to avoid system overload for poly_features and degree=3\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, \n",
    "                           cv=GroupKFold(n_splits=3).split(X_train, y_train, groups=X_train.index.get_level_values(level=\"Instance ID\")), \n",
    "                           scoring=fun_scaled_neg_MAPE, refit=False, verbose=True, n_jobs=cv_n_jobs) # n_jobs=6: 55m, 9s (screen freeze)\n",
    "tuning_details = fun_fit_tuning(grid_search, X_train, y_train, file_name=optimization_problem + \"_PR\")\n",
    "\n",
    "# Estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "model_results_dict = fun_scores(grid_search, X_train, y_train)\n",
    "model_results_dict.update(tuning_details)\n",
    "\n",
    "# View grid search CV scores of all parameter combinations\n",
    "results_df = fun_tuning_results(grid_search, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CVRP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is executed directly. :)\n",
      "Optimization problem: 'CVRP'\n"
     ]
    }
   ],
   "source": [
    "# Set the default optimization problem for the case of manual executing the script (choose either \"TSP\" or \"CVRP\")\n",
    "default_optimization_problem = \"CVRP\"\n",
    "\n",
    "# Call the function to define optimization_problem based on how the notebook is executed\n",
    "# If the notebook is run by the script \"main.ipynb\", load optimization_problem from \"settings.json\". Otherwise use the default optimization problem from above\n",
    "optimization_problem = fun_load_settings(default_optimization_problem)\n",
    "\n",
    "# Load data and start the time count for the script within the function fun_load_data\n",
    "data, start_script = fun_load_data(optimization_problem)\n",
    "\n",
    "# Do the train test split during the preprocessing\n",
    "X_train, X_test, y_train, y_test, train_data = fun_preprocessing(data, train_size=0.8)\n",
    "\n",
    "# Load most important features from script \"b1_feature_selection.ipynb\" and get a list with all features\n",
    "top20_features = list(pd.read_csv(f\"02_best_features/{optimization_problem}_top20_features\"))\n",
    "all_features = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Search type': 'GridSearchCV',\n",
       " 'Parameter combinations': 12,\n",
       " 'Total tuning time': '2h, 18m',\n",
       " 'Total tuning fit time': '1h, 26m',\n",
       " 'Total tuning prediction time': '26s'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAPE (scaled) train data:  5.7608 %\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Best model / parameter combination:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'features': 'Number of features: 42',\n",
       " 'preprocessor__onehot__binning__n_bins': 15,\n",
       " 'preprocessor__poly__degree': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Cross validation scores of different parameter combinations:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessor</th>\n",
       "      <th>n_bins</th>\n",
       "      <th>degree</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>converted_mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.057608</td>\n",
       "      <td>25m, 56s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>27m, 42s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.057829</td>\n",
       "      <td>31m, 30s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.061453</td>\n",
       "      <td>14s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.061517</td>\n",
       "      <td>13s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.061730</td>\n",
       "      <td>11s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.076957</td>\n",
       "      <td>12s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.077256</td>\n",
       "      <td>4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of features: 42</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.077449</td>\n",
       "      <td>5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.087148</td>\n",
       "      <td>2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.087615</td>\n",
       "      <td>2s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>top20_features</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.088359</td>\n",
       "      <td>1s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              preprocessor  n_bins  degree  mean_test_score  \\\n",
       "0   Number of features: 42      15       3        -0.057608   \n",
       "1   Number of features: 42       5       3        -0.057794   \n",
       "2   Number of features: 42      10       3        -0.057829   \n",
       "3           top20_features      15       3        -0.061453   \n",
       "4           top20_features      10       3        -0.061517   \n",
       "5           top20_features       5       3        -0.061730   \n",
       "6   Number of features: 42      15       2        -0.076957   \n",
       "7   Number of features: 42      10       2        -0.077256   \n",
       "8   Number of features: 42       5       2        -0.077449   \n",
       "9           top20_features      15       2        -0.087148   \n",
       "10          top20_features      10       2        -0.087615   \n",
       "11          top20_features       5       2        -0.088359   \n",
       "\n",
       "   converted_mean_fit_time  \n",
       "0                 25m, 56s  \n",
       "1                 27m, 42s  \n",
       "2                 31m, 30s  \n",
       "3                      14s  \n",
       "4                      13s  \n",
       "5                      11s  \n",
       "6                      12s  \n",
       "7                       4s  \n",
       "8                       5s  \n",
       "9                       2s  \n",
       "10                      2s  \n",
       "11                      1s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the preprocessing steps for continuous features\n",
    "onehot_transformer = Pipeline(steps=[(\"binning\", KBinsDiscretizer(encode=\"ordinal\", strategy=\"uniform\")),\n",
    "                                     (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))])\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor_top20 = ColumnTransformer(transformers=[(\"onehot\", onehot_transformer, top20_features), \n",
    "                                                     (\"poly\", PolynomialFeatures(interaction_only=False, include_bias=True), top20_features)], \n",
    "                                                     remainder=\"passthrough\")\n",
    "\n",
    "# Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor_all = ColumnTransformer(transformers=[(\"onehot\", onehot_transformer, top20_features), \n",
    "                                                    (\"poly\", PolynomialFeatures(interaction_only=False, include_bias=True), all_features)], \n",
    "                                                    remainder=\"passthrough\")\n",
    "\n",
    "# Define the model pipeline\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", None),\n",
    "                       (\"lr\", LinearRegression())])\n",
    "\n",
    "param_grid = [{\"preprocessor\": [preprocessor_top20],\n",
    "              \"preprocessor__onehot__binning__n_bins\": [5, 10, 15], \n",
    "              \"preprocessor__poly__degree\": [2, 3]},\n",
    "              {\"preprocessor\": [preprocessor_all],\n",
    "              \"preprocessor__onehot__binning__n_bins\": [5, 10, 15], \n",
    "              \"preprocessor__poly__degree\": [2, 3]}]\n",
    "\n",
    "# Set up GridSearchCV\n",
    "cv_n_jobs = 2 # Reduce number of cores (n_jobs) to avoid system overload for poly_features and degree=3\n",
    "grid_search = GridSearchCV(estimator=pipe, param_grid=param_grid, \n",
    "                           cv=GroupKFold(n_splits=3).split(X_train, y_train, groups=X_train.index.get_level_values(level=\"Instance ID\")), \n",
    "                           scoring=fun_scaled_neg_MAPE, refit=False, verbose=True, n_jobs=cv_n_jobs)\n",
    "tuning_details = fun_fit_tuning(grid_search, X_train, y_train, file_name=optimization_problem + \"_PR\")\n",
    "\n",
    "# Estimate model performance with cross validation on the train set (scoring: MAPE and RMSE)\n",
    "model_results_dict = fun_scores(grid_search, X_train, y_train)\n",
    "model_results_dict.update(tuning_details)\n",
    "\n",
    "# View grid search CV scores of all parameter combinations\n",
    "results_df = fun_tuning_results(grid_search, param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
